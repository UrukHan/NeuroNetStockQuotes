{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PolinomialRegressionKerasTuner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxseK5N/Mk8unVRiMVPSCb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UrukHan/NeuroNetStockQuotes/blob/master/PolinomialRegressionKerasTuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbt9ViQkVF3d",
        "colab_type": "text"
      },
      "source": [
        "## **Импорт библиотек**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGUHDeJHUGXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "f384fa9f-6bf2-4499-a41f-c7923bcd8c1b"
      },
      "source": [
        "# Установка пакетов\n",
        "!pip install -U keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n",
            "\r\u001b[K     |██████                          | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.16.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73200 sha256=c240c4e14a88a85565d0644065e8114c07d13a9a6d7f9b6e365d26d2c751d51e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=66439f8e5adb631c5d29474d8cbfb0749f0ed3bf14d748139d97045d8739b644\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.3 keras-tuner-1.0.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHOMovDPVB1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1d8cac2a-65a0-46e3-8f75-d30fc7399709"
      },
      "source": [
        "# Импорт библиотек\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras import utils\n",
        "from kerastuner.tuners import RandomSearch, Hyperband, BayesianOptimization #\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch \n",
        "from kerastuner import HyperModel \n",
        "from scipy import stats\n",
        "from scipy.stats import norm, skew\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import kerastuner as kt \n",
        "import os\n",
        "\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(tf.__version__)\n",
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULnx_rKOXLXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e4849c2-f0f5-4d68-80d9-17d5e4fa26f5"
      },
      "source": [
        "# Clear logs from previous calls\n",
        "!rm -rf ./logs/ \n",
        "\n",
        "# Check\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcL0QeRPRQ68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Установка начальных значений для операций на основе хэша в python\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "seed=1234\n",
        "\n",
        "# Установка numpy seed\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Установка случайного начального числа в тензорном потоке на уровне графа\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iof1UzfjV8Iq",
        "colab_type": "text"
      },
      "source": [
        "## **Загрузка данных**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7NMEAZ_Xned",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "2fcd668a-d143-4c74-b448-4b6d775dd18c"
      },
      "source": [
        "# Загрузка данных\n",
        "allData = pd.read_json('/content/stockQuotes.json')\n",
        "allData.iloc[:3]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AA</th>\n",
              "      <th>AES</th>\n",
              "      <th>AIG</th>\n",
              "      <th>APA</th>\n",
              "      <th>AUY</th>\n",
              "      <th>AXP</th>\n",
              "      <th>BA</th>\n",
              "      <th>BAC</th>\n",
              "      <th>BBVA</th>\n",
              "      <th>BK</th>\n",
              "      <th>BMY</th>\n",
              "      <th>BWA</th>\n",
              "      <th>C</th>\n",
              "      <th>CAT</th>\n",
              "      <th>CDE</th>\n",
              "      <th>CLF</th>\n",
              "      <th>CNP</th>\n",
              "      <th>COG</th>\n",
              "      <th>CPE</th>\n",
              "      <th>CVX</th>\n",
              "      <th>DAL</th>\n",
              "      <th>DNR</th>\n",
              "      <th>DVN</th>\n",
              "      <th>EMR</th>\n",
              "      <th>EQNR</th>\n",
              "      <th>EQT</th>\n",
              "      <th>F</th>\n",
              "      <th>FCX</th>\n",
              "      <th>FTI</th>\n",
              "      <th>GFI</th>\n",
              "      <th>GLW</th>\n",
              "      <th>GM</th>\n",
              "      <th>GOLD</th>\n",
              "      <th>GPS</th>\n",
              "      <th>GS</th>\n",
              "      <th>HAL</th>\n",
              "      <th>HD</th>\n",
              "      <th>HIG</th>\n",
              "      <th>HL</th>\n",
              "      <th>HOG</th>\n",
              "      <th>...</th>\n",
              "      <th>INFY</th>\n",
              "      <th>IVZ</th>\n",
              "      <th>JPM</th>\n",
              "      <th>KEY</th>\n",
              "      <th>KGC</th>\n",
              "      <th>KIM</th>\n",
              "      <th>KOS</th>\n",
              "      <th>KSS</th>\n",
              "      <th>LUV</th>\n",
              "      <th>LYG</th>\n",
              "      <th>MDT</th>\n",
              "      <th>MGM</th>\n",
              "      <th>MPC</th>\n",
              "      <th>MRO</th>\n",
              "      <th>MS</th>\n",
              "      <th>NE</th>\n",
              "      <th>NLY</th>\n",
              "      <th>NOV</th>\n",
              "      <th>OKE</th>\n",
              "      <th>OXY</th>\n",
              "      <th>PCG</th>\n",
              "      <th>QEP</th>\n",
              "      <th>RF</th>\n",
              "      <th>RIG</th>\n",
              "      <th>RRC</th>\n",
              "      <th>RWT</th>\n",
              "      <th>SAVE</th>\n",
              "      <th>SCHW</th>\n",
              "      <th>SLB</th>\n",
              "      <th>SPG</th>\n",
              "      <th>STT</th>\n",
              "      <th>SWN</th>\n",
              "      <th>TFC</th>\n",
              "      <th>TJX</th>\n",
              "      <th>USB</th>\n",
              "      <th>VER</th>\n",
              "      <th>WFC</th>\n",
              "      <th>WMB</th>\n",
              "      <th>X</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.1230</td>\n",
              "      <td>11.3047</td>\n",
              "      <td>23.9400</td>\n",
              "      <td>5.6824</td>\n",
              "      <td>2.910</td>\n",
              "      <td>87.6466</td>\n",
              "      <td>131.555</td>\n",
              "      <td>21.1288</td>\n",
              "      <td>2.9712</td>\n",
              "      <td>30.1326</td>\n",
              "      <td>51.9017</td>\n",
              "      <td>23.7164</td>\n",
              "      <td>42.0176</td>\n",
              "      <td>96.0501</td>\n",
              "      <td>2.680</td>\n",
              "      <td>4.0417</td>\n",
              "      <td>12.7553</td>\n",
              "      <td>17.510</td>\n",
              "      <td>0.6100</td>\n",
              "      <td>70.6600</td>\n",
              "      <td>36.2451</td>\n",
              "      <td>0.3000</td>\n",
              "      <td>7.6032</td>\n",
              "      <td>47.7785</td>\n",
              "      <td>9.9041</td>\n",
              "      <td>8.7937</td>\n",
              "      <td>5.0721</td>\n",
              "      <td>6.4027</td>\n",
              "      <td>6.2026</td>\n",
              "      <td>4.6800</td>\n",
              "      <td>19.3631</td>\n",
              "      <td>21.5790</td>\n",
              "      <td>16.21</td>\n",
              "      <td>8.3836</td>\n",
              "      <td>156.9206</td>\n",
              "      <td>6.1326</td>\n",
              "      <td>168.2803</td>\n",
              "      <td>34.2243</td>\n",
              "      <td>1.700</td>\n",
              "      <td>21.0388</td>\n",
              "      <td>...</td>\n",
              "      <td>7.4231</td>\n",
              "      <td>8.9637</td>\n",
              "      <td>92.3286</td>\n",
              "      <td>10.2843</td>\n",
              "      <td>4.0800</td>\n",
              "      <td>10.8345</td>\n",
              "      <td>0.8004</td>\n",
              "      <td>19.3081</td>\n",
              "      <td>38.21</td>\n",
              "      <td>1.5907</td>\n",
              "      <td>79.2731</td>\n",
              "      <td>10.9246</td>\n",
              "      <td>20.8287</td>\n",
              "      <td>4.1517</td>\n",
              "      <td>32.3835</td>\n",
              "      <td>0.2801</td>\n",
              "      <td>6.9629</td>\n",
              "      <td>9.2639</td>\n",
              "      <td>25.02</td>\n",
              "      <td>12.39</td>\n",
              "      <td>9.5538</td>\n",
              "      <td>0.6403</td>\n",
              "      <td>8.4635</td>\n",
              "      <td>1.3206</td>\n",
              "      <td>2.8112</td>\n",
              "      <td>9.3939</td>\n",
              "      <td>12.1051</td>\n",
              "      <td>31.3681</td>\n",
              "      <td>14.5361</td>\n",
              "      <td>66.9900</td>\n",
              "      <td>49.1805</td>\n",
              "      <td>1.9208</td>\n",
              "      <td>28.2918</td>\n",
              "      <td>41.4655</td>\n",
              "      <td>33.3839</td>\n",
              "      <td>5.6223</td>\n",
              "      <td>27.5515</td>\n",
              "      <td>13.5757</td>\n",
              "      <td>5.4423</td>\n",
              "      <td>35.3148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.9322</td>\n",
              "      <td>9.9900</td>\n",
              "      <td>21.0667</td>\n",
              "      <td>4.8215</td>\n",
              "      <td>3.345</td>\n",
              "      <td>85.1671</td>\n",
              "      <td>110.215</td>\n",
              "      <td>20.8516</td>\n",
              "      <td>2.9550</td>\n",
              "      <td>29.2243</td>\n",
              "      <td>52.6367</td>\n",
              "      <td>22.0970</td>\n",
              "      <td>40.6229</td>\n",
              "      <td>95.5804</td>\n",
              "      <td>3.246</td>\n",
              "      <td>4.1944</td>\n",
              "      <td>12.4540</td>\n",
              "      <td>18.766</td>\n",
              "      <td>0.5413</td>\n",
              "      <td>67.1113</td>\n",
              "      <td>33.9508</td>\n",
              "      <td>0.2885</td>\n",
              "      <td>7.3173</td>\n",
              "      <td>46.7549</td>\n",
              "      <td>9.8500</td>\n",
              "      <td>9.2500</td>\n",
              "      <td>4.7815</td>\n",
              "      <td>6.1100</td>\n",
              "      <td>5.9519</td>\n",
              "      <td>5.2367</td>\n",
              "      <td>18.9550</td>\n",
              "      <td>19.9563</td>\n",
              "      <td>17.46</td>\n",
              "      <td>7.4874</td>\n",
              "      <td>153.7300</td>\n",
              "      <td>5.7300</td>\n",
              "      <td>161.3413</td>\n",
              "      <td>32.5003</td>\n",
              "      <td>2.045</td>\n",
              "      <td>20.4265</td>\n",
              "      <td>...</td>\n",
              "      <td>7.4300</td>\n",
              "      <td>8.4100</td>\n",
              "      <td>89.9638</td>\n",
              "      <td>9.6281</td>\n",
              "      <td>4.5815</td>\n",
              "      <td>10.3533</td>\n",
              "      <td>0.6703</td>\n",
              "      <td>16.5503</td>\n",
              "      <td>36.18</td>\n",
              "      <td>1.5955</td>\n",
              "      <td>78.9251</td>\n",
              "      <td>10.1732</td>\n",
              "      <td>18.9760</td>\n",
              "      <td>4.0613</td>\n",
              "      <td>31.1800</td>\n",
              "      <td>0.2972</td>\n",
              "      <td>6.6062</td>\n",
              "      <td>8.5800</td>\n",
              "      <td>22.88</td>\n",
              "      <td>11.65</td>\n",
              "      <td>9.2300</td>\n",
              "      <td>0.5197</td>\n",
              "      <td>8.3176</td>\n",
              "      <td>1.2700</td>\n",
              "      <td>3.0200</td>\n",
              "      <td>8.3577</td>\n",
              "      <td>11.2436</td>\n",
              "      <td>29.9695</td>\n",
              "      <td>13.5393</td>\n",
              "      <td>60.9694</td>\n",
              "      <td>46.9049</td>\n",
              "      <td>2.3150</td>\n",
              "      <td>27.3187</td>\n",
              "      <td>40.2328</td>\n",
              "      <td>31.7351</td>\n",
              "      <td>5.3517</td>\n",
              "      <td>27.5267</td>\n",
              "      <td>13.1542</td>\n",
              "      <td>6.0969</td>\n",
              "      <td>36.1615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0700</td>\n",
              "      <td>10.6100</td>\n",
              "      <td>21.3200</td>\n",
              "      <td>5.1650</td>\n",
              "      <td>3.530</td>\n",
              "      <td>85.4300</td>\n",
              "      <td>112.830</td>\n",
              "      <td>21.2050</td>\n",
              "      <td>3.0500</td>\n",
              "      <td>29.6000</td>\n",
              "      <td>53.0000</td>\n",
              "      <td>21.7800</td>\n",
              "      <td>42.3200</td>\n",
              "      <td>96.8900</td>\n",
              "      <td>3.460</td>\n",
              "      <td>4.1350</td>\n",
              "      <td>12.7800</td>\n",
              "      <td>18.800</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>68.4100</td>\n",
              "      <td>34.2200</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>7.7800</td>\n",
              "      <td>47.2100</td>\n",
              "      <td>10.2600</td>\n",
              "      <td>9.0850</td>\n",
              "      <td>4.9500</td>\n",
              "      <td>6.0500</td>\n",
              "      <td>6.0900</td>\n",
              "      <td>5.3100</td>\n",
              "      <td>20.5388</td>\n",
              "      <td>20.3400</td>\n",
              "      <td>18.12</td>\n",
              "      <td>7.6150</td>\n",
              "      <td>161.4350</td>\n",
              "      <td>6.0800</td>\n",
              "      <td>164.7600</td>\n",
              "      <td>31.2600</td>\n",
              "      <td>2.100</td>\n",
              "      <td>21.0100</td>\n",
              "      <td>...</td>\n",
              "      <td>7.5750</td>\n",
              "      <td>8.8900</td>\n",
              "      <td>92.1200</td>\n",
              "      <td>9.9500</td>\n",
              "      <td>4.7600</td>\n",
              "      <td>10.5700</td>\n",
              "      <td>0.7600</td>\n",
              "      <td>17.3300</td>\n",
              "      <td>37.82</td>\n",
              "      <td>1.5900</td>\n",
              "      <td>78.1600</td>\n",
              "      <td>10.1200</td>\n",
              "      <td>20.4900</td>\n",
              "      <td>4.0500</td>\n",
              "      <td>33.1600</td>\n",
              "      <td>0.3000</td>\n",
              "      <td>6.6650</td>\n",
              "      <td>9.5500</td>\n",
              "      <td>22.13</td>\n",
              "      <td>12.37</td>\n",
              "      <td>9.5900</td>\n",
              "      <td>0.5400</td>\n",
              "      <td>8.5800</td>\n",
              "      <td>1.3400</td>\n",
              "      <td>3.0101</td>\n",
              "      <td>7.8300</td>\n",
              "      <td>11.2200</td>\n",
              "      <td>31.0300</td>\n",
              "      <td>13.7100</td>\n",
              "      <td>60.7900</td>\n",
              "      <td>48.7000</td>\n",
              "      <td>2.2300</td>\n",
              "      <td>29.1100</td>\n",
              "      <td>41.9000</td>\n",
              "      <td>33.3400</td>\n",
              "      <td>5.3900</td>\n",
              "      <td>29.3400</td>\n",
              "      <td>12.5100</td>\n",
              "      <td>6.0000</td>\n",
              "      <td>37.0300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 83 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       AA      AES      AIG     APA  ...      WFC      WMB       X      XOM\n",
              "0  7.1230  11.3047  23.9400  5.6824  ...  27.5515  13.5757  5.4423  35.3148\n",
              "1  6.9322   9.9900  21.0667  4.8215  ...  27.5267  13.1542  6.0969  36.1615\n",
              "2  7.0700  10.6100  21.3200  5.1650  ...  29.3400  12.5100  6.0000  37.0300\n",
              "\n",
              "[3 rows x 83 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTDo8Q8Fa8cf",
        "colab_type": "text"
      },
      "source": [
        "## **# Подготовка данных к использованию сетью**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjE0LEAhCHYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "c0286252-93c4-40d5-c255-2856938352fb"
      },
      "source": [
        "# Создание копии таблицы данных\n",
        "dataSetFull = allData.copy()\n",
        "# Заменяем значения таблицы на значения равным разнице между строками\n",
        "dataSetFull = dataSetFull.diff().shift(-1)\n",
        "dataSetFull = dataSetFull.dropna()\n",
        "dataSetFull.head(3)"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AA</th>\n",
              "      <th>AES</th>\n",
              "      <th>AIG</th>\n",
              "      <th>APA</th>\n",
              "      <th>AUY</th>\n",
              "      <th>AXP</th>\n",
              "      <th>BA</th>\n",
              "      <th>BAC</th>\n",
              "      <th>BBVA</th>\n",
              "      <th>BK</th>\n",
              "      <th>BMY</th>\n",
              "      <th>BWA</th>\n",
              "      <th>C</th>\n",
              "      <th>CAT</th>\n",
              "      <th>CDE</th>\n",
              "      <th>CLF</th>\n",
              "      <th>CNP</th>\n",
              "      <th>COG</th>\n",
              "      <th>CPE</th>\n",
              "      <th>CVX</th>\n",
              "      <th>DAL</th>\n",
              "      <th>DNR</th>\n",
              "      <th>DVN</th>\n",
              "      <th>EMR</th>\n",
              "      <th>EQNR</th>\n",
              "      <th>EQT</th>\n",
              "      <th>F</th>\n",
              "      <th>FCX</th>\n",
              "      <th>FTI</th>\n",
              "      <th>GFI</th>\n",
              "      <th>GLW</th>\n",
              "      <th>GM</th>\n",
              "      <th>GOLD</th>\n",
              "      <th>GPS</th>\n",
              "      <th>GS</th>\n",
              "      <th>HAL</th>\n",
              "      <th>HD</th>\n",
              "      <th>HIG</th>\n",
              "      <th>HL</th>\n",
              "      <th>HOG</th>\n",
              "      <th>...</th>\n",
              "      <th>INFY</th>\n",
              "      <th>IVZ</th>\n",
              "      <th>JPM</th>\n",
              "      <th>KEY</th>\n",
              "      <th>KGC</th>\n",
              "      <th>KIM</th>\n",
              "      <th>KOS</th>\n",
              "      <th>KSS</th>\n",
              "      <th>LUV</th>\n",
              "      <th>LYG</th>\n",
              "      <th>MDT</th>\n",
              "      <th>MGM</th>\n",
              "      <th>MPC</th>\n",
              "      <th>MRO</th>\n",
              "      <th>MS</th>\n",
              "      <th>NE</th>\n",
              "      <th>NLY</th>\n",
              "      <th>NOV</th>\n",
              "      <th>OKE</th>\n",
              "      <th>OXY</th>\n",
              "      <th>PCG</th>\n",
              "      <th>QEP</th>\n",
              "      <th>RF</th>\n",
              "      <th>RIG</th>\n",
              "      <th>RRC</th>\n",
              "      <th>RWT</th>\n",
              "      <th>SAVE</th>\n",
              "      <th>SCHW</th>\n",
              "      <th>SLB</th>\n",
              "      <th>SPG</th>\n",
              "      <th>STT</th>\n",
              "      <th>SWN</th>\n",
              "      <th>TFC</th>\n",
              "      <th>TJX</th>\n",
              "      <th>USB</th>\n",
              "      <th>VER</th>\n",
              "      <th>WFC</th>\n",
              "      <th>WMB</th>\n",
              "      <th>X</th>\n",
              "      <th>XOM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.1908</td>\n",
              "      <td>-1.3147</td>\n",
              "      <td>-2.8733</td>\n",
              "      <td>-0.8609</td>\n",
              "      <td>0.4350</td>\n",
              "      <td>-2.4795</td>\n",
              "      <td>-21.3400</td>\n",
              "      <td>-0.2772</td>\n",
              "      <td>-0.0162</td>\n",
              "      <td>-0.9083</td>\n",
              "      <td>0.7350</td>\n",
              "      <td>-1.6194</td>\n",
              "      <td>-1.3947</td>\n",
              "      <td>-0.4697</td>\n",
              "      <td>0.5660</td>\n",
              "      <td>0.1527</td>\n",
              "      <td>-0.3013</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>-0.0687</td>\n",
              "      <td>-3.5487</td>\n",
              "      <td>-2.2943</td>\n",
              "      <td>-0.0115</td>\n",
              "      <td>-0.2859</td>\n",
              "      <td>-1.0236</td>\n",
              "      <td>-0.0541</td>\n",
              "      <td>0.4563</td>\n",
              "      <td>-0.2906</td>\n",
              "      <td>-0.2927</td>\n",
              "      <td>-0.2507</td>\n",
              "      <td>0.5567</td>\n",
              "      <td>-0.4081</td>\n",
              "      <td>-1.6227</td>\n",
              "      <td>1.2500</td>\n",
              "      <td>-0.8962</td>\n",
              "      <td>-3.1906</td>\n",
              "      <td>-0.4026</td>\n",
              "      <td>-6.9390</td>\n",
              "      <td>-1.7240</td>\n",
              "      <td>0.3450</td>\n",
              "      <td>-0.6123</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0069</td>\n",
              "      <td>-0.5537</td>\n",
              "      <td>-2.3648</td>\n",
              "      <td>-0.6562</td>\n",
              "      <td>0.5015</td>\n",
              "      <td>-0.4812</td>\n",
              "      <td>-0.1301</td>\n",
              "      <td>-2.7578</td>\n",
              "      <td>-2.0300</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>-0.3480</td>\n",
              "      <td>-0.7514</td>\n",
              "      <td>-1.8527</td>\n",
              "      <td>-0.0904</td>\n",
              "      <td>-1.2035</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>-0.3567</td>\n",
              "      <td>-0.6839</td>\n",
              "      <td>-2.14</td>\n",
              "      <td>-0.7400</td>\n",
              "      <td>-0.3238</td>\n",
              "      <td>-0.1206</td>\n",
              "      <td>-0.1459</td>\n",
              "      <td>-0.0506</td>\n",
              "      <td>0.2088</td>\n",
              "      <td>-1.0362</td>\n",
              "      <td>-0.8615</td>\n",
              "      <td>-1.3986</td>\n",
              "      <td>-0.9968</td>\n",
              "      <td>-6.0206</td>\n",
              "      <td>-2.2756</td>\n",
              "      <td>0.3942</td>\n",
              "      <td>-0.9731</td>\n",
              "      <td>-1.2327</td>\n",
              "      <td>-1.6488</td>\n",
              "      <td>-0.2706</td>\n",
              "      <td>-0.0248</td>\n",
              "      <td>-0.4215</td>\n",
              "      <td>0.6546</td>\n",
              "      <td>0.8467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1378</td>\n",
              "      <td>0.6200</td>\n",
              "      <td>0.2533</td>\n",
              "      <td>0.3435</td>\n",
              "      <td>0.1850</td>\n",
              "      <td>0.2629</td>\n",
              "      <td>2.6150</td>\n",
              "      <td>0.3534</td>\n",
              "      <td>0.0950</td>\n",
              "      <td>0.3757</td>\n",
              "      <td>0.3633</td>\n",
              "      <td>-0.3170</td>\n",
              "      <td>1.6971</td>\n",
              "      <td>1.3096</td>\n",
              "      <td>0.2140</td>\n",
              "      <td>-0.0594</td>\n",
              "      <td>0.3260</td>\n",
              "      <td>0.0340</td>\n",
              "      <td>0.0287</td>\n",
              "      <td>1.2987</td>\n",
              "      <td>0.2692</td>\n",
              "      <td>0.0215</td>\n",
              "      <td>0.4627</td>\n",
              "      <td>0.4551</td>\n",
              "      <td>0.4100</td>\n",
              "      <td>-0.1650</td>\n",
              "      <td>0.1685</td>\n",
              "      <td>-0.0600</td>\n",
              "      <td>0.1381</td>\n",
              "      <td>0.0733</td>\n",
              "      <td>1.5838</td>\n",
              "      <td>0.3837</td>\n",
              "      <td>0.6600</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>7.7050</td>\n",
              "      <td>0.3500</td>\n",
              "      <td>3.4187</td>\n",
              "      <td>-1.2403</td>\n",
              "      <td>0.0550</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1450</td>\n",
              "      <td>0.4800</td>\n",
              "      <td>2.1562</td>\n",
              "      <td>0.3219</td>\n",
              "      <td>0.1785</td>\n",
              "      <td>0.2167</td>\n",
              "      <td>0.0897</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>1.6400</td>\n",
              "      <td>-0.0055</td>\n",
              "      <td>-0.7651</td>\n",
              "      <td>-0.0532</td>\n",
              "      <td>1.5140</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>1.9800</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0588</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.7200</td>\n",
              "      <td>0.3600</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.2624</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>-0.0099</td>\n",
              "      <td>-0.5277</td>\n",
              "      <td>-0.0236</td>\n",
              "      <td>1.0605</td>\n",
              "      <td>0.1707</td>\n",
              "      <td>-0.1794</td>\n",
              "      <td>1.7951</td>\n",
              "      <td>-0.0850</td>\n",
              "      <td>1.7913</td>\n",
              "      <td>1.6672</td>\n",
              "      <td>1.6049</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>1.8133</td>\n",
              "      <td>-0.6442</td>\n",
              "      <td>-0.0969</td>\n",
              "      <td>0.8685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.0181</td>\n",
              "      <td>0.3300</td>\n",
              "      <td>0.5858</td>\n",
              "      <td>-0.1050</td>\n",
              "      <td>-0.1691</td>\n",
              "      <td>1.3800</td>\n",
              "      <td>4.3408</td>\n",
              "      <td>0.8008</td>\n",
              "      <td>0.0300</td>\n",
              "      <td>-0.4623</td>\n",
              "      <td>-0.2811</td>\n",
              "      <td>0.1858</td>\n",
              "      <td>-0.2864</td>\n",
              "      <td>1.9300</td>\n",
              "      <td>-0.1991</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>-0.0850</td>\n",
              "      <td>0.6051</td>\n",
              "      <td>-0.0190</td>\n",
              "      <td>1.0400</td>\n",
              "      <td>1.0800</td>\n",
              "      <td>-0.0078</td>\n",
              "      <td>-0.1900</td>\n",
              "      <td>-0.8650</td>\n",
              "      <td>-0.0200</td>\n",
              "      <td>0.2124</td>\n",
              "      <td>0.1563</td>\n",
              "      <td>0.1850</td>\n",
              "      <td>-0.0600</td>\n",
              "      <td>-0.1236</td>\n",
              "      <td>-0.4488</td>\n",
              "      <td>0.4700</td>\n",
              "      <td>-0.5204</td>\n",
              "      <td>0.6322</td>\n",
              "      <td>-1.5450</td>\n",
              "      <td>0.1094</td>\n",
              "      <td>5.4347</td>\n",
              "      <td>1.1285</td>\n",
              "      <td>-0.1895</td>\n",
              "      <td>1.0058</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1700</td>\n",
              "      <td>0.5500</td>\n",
              "      <td>2.5100</td>\n",
              "      <td>-0.0050</td>\n",
              "      <td>-0.1488</td>\n",
              "      <td>0.2528</td>\n",
              "      <td>-0.0297</td>\n",
              "      <td>0.6100</td>\n",
              "      <td>0.7301</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>1.1403</td>\n",
              "      <td>0.4100</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>-0.0400</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>0.0038</td>\n",
              "      <td>-0.1100</td>\n",
              "      <td>-0.1900</td>\n",
              "      <td>0.97</td>\n",
              "      <td>-0.0268</td>\n",
              "      <td>-0.1000</td>\n",
              "      <td>-0.0383</td>\n",
              "      <td>0.5200</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>0.0407</td>\n",
              "      <td>0.0421</td>\n",
              "      <td>0.1466</td>\n",
              "      <td>0.5583</td>\n",
              "      <td>0.3887</td>\n",
              "      <td>0.3931</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>-0.0944</td>\n",
              "      <td>-0.3300</td>\n",
              "      <td>0.9113</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>-0.0386</td>\n",
              "      <td>-0.3024</td>\n",
              "      <td>0.4084</td>\n",
              "      <td>0.0850</td>\n",
              "      <td>-0.5690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 83 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       AA     AES     AIG     APA  ...     WFC     WMB       X     XOM\n",
              "0 -0.1908 -1.3147 -2.8733 -0.8609  ... -0.0248 -0.4215  0.6546  0.8467\n",
              "1  0.1378  0.6200  0.2533  0.3435  ...  1.8133 -0.6442 -0.0969  0.8685\n",
              "2 -0.0181  0.3300  0.5858 -0.1050  ... -0.3024  0.4084  0.0850 -0.5690\n",
              "\n",
              "[3 rows x 83 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUxMSrxI-DKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция соднаия последовательной модели\n",
        "def modelTF():\n",
        "  model = Sequential()\n",
        "  # Добавляем уровни сети\n",
        "  model.add(Dense(2048, input_dim = dataSetFull.shape[1] - 1, activation=\"relu\"))\n",
        "  model.add(Dense(1024, activation = \"relu\"))\n",
        "  model.add(Dense(512, activation = \"relu\"))\n",
        "  model.add(Dense(256, activation = \"relu\"))\n",
        "  model.add(layers.Dropout(0.05))\n",
        "  model.add(Dense(1))\n",
        "  # Компилируем сеть и задаем оптимизатор\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.000005)\n",
        "  model.compile(loss = 'mse', optimizer = optimizer, metrics = [\"mse\", \"mae\"])\n",
        "#  print (model.summary())\n",
        "  return model"
      ],
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXLVkXkO9_Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Класс отображения хода обучения сети\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 15 == 0: print('')\n",
        "    print('.', end = '')"
      ],
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNNhzaTcqT_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crossValdation(dataSet, modelTF, arg):\n",
        "  epohs = 5\n",
        "  batch = 20\n",
        "  histMean = pd.DataFrame({'loss':[], 'mse':[], 'mae':[], 'val_loss':[], 'val_mse':[], 'val_mae':[], 'epoch':[]})\n",
        "  kf = KFold(n_splits=5, shuffle = True, random_state = 42)\n",
        "  for train_index, validation_index in kf.split(dataSet):\n",
        "    trainData = dataSet.iloc[train_index]\n",
        "    validationData =  dataSet.iloc[validation_index]\n",
        "    model = modelTF()\n",
        "    early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
        "    history = model.fit(\n",
        "      trainData.drop([arg], axis = 1, inplace = False), trainData[arg], batch_size = BATCH,\n",
        "      epochs=EPOCHS,  validation_data = (validationData.drop([arg], axis = 1, inplace = False), validationData[arg]), verbose = 0)\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    hist['epoch'] = history.epoch\n",
        "    histMean = histMean.append(hist.iloc[[-1]], ignore_index=True)\n",
        "  del histMean['epoch']\n",
        "  historyBias = pd.DataFrame(histMean.mean()).T\n",
        "  return historyBias"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NEHNtpFqTfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция подбора лучших значений смещений(bias) по параметрам (arg)\n",
        "def testBias(allArg, dataSet, crossValdation, modelTF): # списокКомпаний/датаСет/функцияКроссВалидации/модельНС\n",
        "  maxBias = int(input('Max bias Y   -   '))\n",
        "  historyBias = pd.DataFrame({'loss':[], 'mse':[], 'mae':[], 'val_loss':[], 'val_mse':[], 'val_mae':[]})\n",
        "  biasAll = pd.DataFrame({'Bias':[]})\n",
        "  argAll = pd.DataFrame({'Company':[]})\n",
        "  dataSetFull = dataSet.copy()\n",
        "  for arg in allArg:     #  Проход по переменным модели для вычисления лучшего значения смещений\n",
        "    bias = pd.DataFrame({'Bias':[]})\n",
        "    argum = pd.DataFrame({'Company':[]})\n",
        "    for b in range(1, maxBias + 1): \n",
        "      if b > 1:\n",
        "        dataSetFull = dataSet.copy()\n",
        "      dataSet = dataSetFull.copy()\n",
        "      dataSetBiasArg = dataSet[arg]\n",
        "      dataSetBiasArg = dataSetBiasArg[b:].reset_index()\n",
        "      del dataSetBiasArg['index']\n",
        "      dataSetWithoutArg = dataSet.copy()\n",
        "      del dataSetWithoutArg[arg]\n",
        "      dataSet = pd.concat([dataSetWithoutArg, dataSetBiasArg], axis=1)\n",
        "      dataSet = dataSet.dropna()\n",
        "      historyBias = historyBias.append(crossValdation(dataSet, modelTF, arg), ignore_index=True)   # Получение значений кросс валидации\n",
        "      bias = bias.append(pd.DataFrame({'Bias':[b]}), ignore_index=True)\n",
        "      argum = argum.append(pd.DataFrame({'Company':[arg]}), ignore_index=True)\n",
        "      dataSet = dataSetFull.copy()  # Откат значений таблицы\n",
        "    biasAll = biasAll.append(bias, ignore_index=True)\n",
        "    argAll = argAll.append(argum, ignore_index=True)\n",
        "  HB = pd.concat([historyBias, biasAll, argAll], axis=1)\n",
        "  return HB"
      ],
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtzWM8ooqTFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "c58c48a8-6a6f-40f2-912b-dbc692871a02"
      },
      "source": [
        "parametres =  dataSetFull.columns.tolist()\n",
        "qualityBias = testBias(parametres, dataSetFull, crossValdation, modelTF)"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max bias Y   -   2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mse</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mse</th>\n",
              "      <th>val_mae</th>\n",
              "      <th>Bias</th>\n",
              "      <th>Company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.043180</td>\n",
              "      <td>0.043180</td>\n",
              "      <td>0.163501</td>\n",
              "      <td>0.045575</td>\n",
              "      <td>0.045575</td>\n",
              "      <td>0.168173</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.047937</td>\n",
              "      <td>0.047937</td>\n",
              "      <td>0.171124</td>\n",
              "      <td>0.056134</td>\n",
              "      <td>0.056134</td>\n",
              "      <td>0.178723</td>\n",
              "      <td>2.0</td>\n",
              "      <td>AA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.291006</td>\n",
              "      <td>0.291006</td>\n",
              "      <td>0.431512</td>\n",
              "      <td>0.324742</td>\n",
              "      <td>0.324742</td>\n",
              "      <td>0.450524</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.296432</td>\n",
              "      <td>0.296432</td>\n",
              "      <td>0.429217</td>\n",
              "      <td>0.280142</td>\n",
              "      <td>0.280142</td>\n",
              "      <td>0.415803</td>\n",
              "      <td>2.0</td>\n",
              "      <td>AES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.926726</td>\n",
              "      <td>0.926726</td>\n",
              "      <td>0.690036</td>\n",
              "      <td>0.989736</td>\n",
              "      <td>0.989736</td>\n",
              "      <td>0.725538</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.963598</td>\n",
              "      <td>0.963598</td>\n",
              "      <td>0.715718</td>\n",
              "      <td>1.100283</td>\n",
              "      <td>1.100283</td>\n",
              "      <td>0.766229</td>\n",
              "      <td>2.0</td>\n",
              "      <td>AIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.077040</td>\n",
              "      <td>0.077040</td>\n",
              "      <td>0.232590</td>\n",
              "      <td>0.085265</td>\n",
              "      <td>0.085265</td>\n",
              "      <td>0.250742</td>\n",
              "      <td>1.0</td>\n",
              "      <td>APA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.080416</td>\n",
              "      <td>0.080416</td>\n",
              "      <td>0.234795</td>\n",
              "      <td>0.086460</td>\n",
              "      <td>0.086460</td>\n",
              "      <td>0.235249</td>\n",
              "      <td>2.0</td>\n",
              "      <td>APA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.026921</td>\n",
              "      <td>0.026921</td>\n",
              "      <td>0.118302</td>\n",
              "      <td>0.028347</td>\n",
              "      <td>0.028347</td>\n",
              "      <td>0.114593</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.029813</td>\n",
              "      <td>0.029813</td>\n",
              "      <td>0.120963</td>\n",
              "      <td>0.030389</td>\n",
              "      <td>0.030389</td>\n",
              "      <td>0.118024</td>\n",
              "      <td>2.0</td>\n",
              "      <td>AUY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.177706</td>\n",
              "      <td>6.177706</td>\n",
              "      <td>2.025002</td>\n",
              "      <td>6.271389</td>\n",
              "      <td>6.271389</td>\n",
              "      <td>2.060520</td>\n",
              "      <td>1.0</td>\n",
              "      <td>AXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.549902</td>\n",
              "      <td>6.549902</td>\n",
              "      <td>2.124456</td>\n",
              "      <td>7.204844</td>\n",
              "      <td>7.204844</td>\n",
              "      <td>2.247627</td>\n",
              "      <td>2.0</td>\n",
              "      <td>AXP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss       mse       mae  val_loss   val_mse   val_mae  Bias Company\n",
              "0   0.043180  0.043180  0.163501  0.045575  0.045575  0.168173   1.0      AA\n",
              "1   0.047937  0.047937  0.171124  0.056134  0.056134  0.178723   2.0      AA\n",
              "2   0.291006  0.291006  0.431512  0.324742  0.324742  0.450524   1.0     AES\n",
              "3   0.296432  0.296432  0.429217  0.280142  0.280142  0.415803   2.0     AES\n",
              "4   0.926726  0.926726  0.690036  0.989736  0.989736  0.725538   1.0     AIG\n",
              "5   0.963598  0.963598  0.715718  1.100283  1.100283  0.766229   2.0     AIG\n",
              "6   0.077040  0.077040  0.232590  0.085265  0.085265  0.250742   1.0     APA\n",
              "7   0.080416  0.080416  0.234795  0.086460  0.086460  0.235249   2.0     APA\n",
              "8   0.026921  0.026921  0.118302  0.028347  0.028347  0.114593   1.0     AUY\n",
              "9   0.029813  0.029813  0.120963  0.030389  0.030389  0.118024   2.0     AUY\n",
              "10  6.177706  6.177706  2.025002  6.271389  6.271389  2.060520   1.0     AXP\n",
              "11  6.549902  6.549902  2.124456  7.204844  7.204844  2.247627   2.0     AXP"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le1d5ogEqS03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qualityBias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRe6zOdnqSgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV1JV85lq50Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d71a00f-4e01-41d8-fc7c-9a74d6dc8b4a"
      },
      "source": [
        "# Обучаем модель с сохранением истории обучения\n",
        "epohs = 5\n",
        "batch = 20\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 42)\n",
        "historys = pd.DataFrame({'loss':[], 'mse':[], 'mae':[], 'val_loss':[], 'val_mse':[], 'val_mae':[], 'epoch':[]})\n",
        "historysForGraph = pd.DataFrame({'loss':[0], 'mse':[0], 'mae':[0], 'val_loss':[0], 'val_mse':[0], 'val_mae':[0], 'epoch':[0]})\n",
        "for i in range(epohs - 1):\n",
        "  historysForGraph = historysForGraph.append(pd.DataFrame({'loss':[0], 'mse':[0], 'mae':[0], 'val_loss':[0], 'val_mse':[0], 'val_mae':[0], 'epoch':[0]}), ignore_index=True)\n",
        "historysForGraph\n",
        "for train_index, validation_index in kf.split(dataSetFull):\n",
        "  trainData = dataSetFull.iloc[train_index]\n",
        "  validationData =  dataSetFull.iloc[validation_index]\n",
        "  model = modelTF()\n",
        "  early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
        "  history = model.fit(\n",
        "    trainData.drop(['AA'], axis = 1, inplace = False), trainData[\"AA\"], batch_size = batch,\n",
        "    epochs=epohs,  validation_data = (validationData.drop(['AA'], axis = 1, inplace = False), validationData[\"AA\"]), verbose = 0,\n",
        "    callbacks = [early_stop, PrintDot()])\n",
        "  # Вывод истории обучения\n",
        "  print ('\\n')\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "  historys = historys.append(hist.iloc[[-1]], ignore_index=True)\n",
        "  historysForGraph = historysForGraph + hist\n",
        "  print (hist)\n",
        "  # Предсказание значений\n",
        "  preds_test = model.predict(validationData.drop(['AA'], axis = 1, inplace = False)).flatten()\n",
        "  # Просмотр прогноза\n",
        "  predsData = model.predict(validationData.drop(['AA'], axis = 1, inplace = False))\n",
        "  for i in range(5):\n",
        "    print(\"Предсказанный рост:\", round(predsData[i][0], 3), \", правильный рост:\", round(validationData[\"AA\"].values[i], 3))\n",
        "del historys['epoch']"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ".....\n",
            "\n",
            "       loss       mse       mae  val_loss   val_mse   val_mae  epoch\n",
            "0  0.062080  0.062080  0.163535  0.031772  0.031772  0.124496      0\n",
            "1  0.024427  0.024427  0.107966  0.019657  0.019657  0.100390      1\n",
            "2  0.021171  0.021171  0.095987  0.018301  0.018301  0.098809      2\n",
            "3  0.017903  0.017903  0.091208  0.017705  0.017705  0.096974      3\n",
            "4  0.015729  0.015729  0.087367  0.017134  0.017134  0.095159      4\n",
            "Предсказанный рост: -0.392 , правильный рост: -0.191\n",
            "Предсказанный рост: -0.026 , правильный рост: -0.156\n",
            "Предсказанный рост: 0.094 , правильный рост: 0.055\n",
            "Предсказанный рост: 0.061 , правильный рост: -0.01\n",
            "Предсказанный рост: -0.005 , правильный рост: -0.034\n",
            "\n",
            ".....\n",
            "\n",
            "       loss       mse       mae  val_loss   val_mse   val_mae  epoch\n",
            "0  0.056960  0.056960  0.162127  0.047245  0.047245  0.138643      0\n",
            "1  0.027630  0.027630  0.116521  0.028562  0.028562  0.111897      1\n",
            "2  0.020946  0.020946  0.101829  0.023023  0.023023  0.103074      2\n",
            "3  0.018280  0.018280  0.095981  0.021135  0.021135  0.099078      3\n",
            "4  0.016644  0.016644  0.091123  0.021145  0.021145  0.098772      4\n",
            "Предсказанный рост: -0.248 , правильный рост: -0.206\n",
            "Предсказанный рост: -0.244 , правильный рост: -0.045\n",
            "Предсказанный рост: -0.271 , правильный рост: -0.455\n",
            "Предсказанный рост: 0.137 , правильный рост: -0.26\n",
            "Предсказанный рост: -0.219 , правильный рост: 0.026\n",
            "\n",
            ".....\n",
            "\n",
            "       loss       mse       mae  val_loss   val_mse   val_mae  epoch\n",
            "0  0.046163  0.046163  0.148281  0.028091  0.028091  0.105705      0\n",
            "1  0.026515  0.026515  0.116768  0.019227  0.019227  0.087948      1\n",
            "2  0.020707  0.020707  0.100976  0.016540  0.016540  0.082733      2\n",
            "3  0.018483  0.018483  0.096676  0.015483  0.015483  0.082305      3\n",
            "4  0.016143  0.016143  0.090272  0.014809  0.014809  0.080091      4\n",
            "Предсказанный рост: 0.134 , правильный рост: -0.018\n",
            "Предсказанный рост: -0.282 , правильный рост: -0.322\n",
            "Предсказанный рост: -0.177 , правильный рост: 0.178\n",
            "Предсказанный рост: -0.124 , правильный рост: -0.24\n",
            "Предсказанный рост: 0.128 , правильный рост: 0.062\n",
            "\n",
            ".....\n",
            "\n",
            "       loss       mse       mae  val_loss   val_mse   val_mae  epoch\n",
            "0  0.046447  0.046447  0.146532  0.036978  0.036978  0.126301      0\n",
            "1  0.021969  0.021969  0.104978  0.030287  0.030287  0.102616      1\n",
            "2  0.019312  0.019312  0.096568  0.029405  0.029405  0.101429      2\n",
            "3  0.017287  0.017287  0.092017  0.028905  0.028905  0.101619      3\n",
            "4  0.015125  0.015125  0.087382  0.028137  0.028137  0.101004      4\n",
            "Предсказанный рост: 0.051 , правильный рост: 0.184\n",
            "Предсказанный рост: -0.125 , правильный рост: -0.38\n",
            "Предсказанный рост: 0.186 , правильный рост: -0.204\n",
            "Предсказанный рост: 0.2 , правильный рост: 0.11\n",
            "Предсказанный рост: 0.037 , правильный рост: -0.148\n",
            "\n",
            ".....\n",
            "\n",
            "       loss       mse       mae  val_loss   val_mse   val_mae  epoch\n",
            "0  0.049776  0.049776  0.148569  0.026522  0.026522  0.125466      0\n",
            "1  0.021982  0.021982  0.103849  0.022761  0.022761  0.110457      1\n",
            "2  0.016242  0.016242  0.089881  0.023224  0.023224  0.109738      2\n",
            "3  0.013423  0.013423  0.083672  0.021507  0.021507  0.107033      3\n",
            "4  0.012592  0.012592  0.081386  0.020805  0.020805  0.106737      4\n",
            "Предсказанный рост: 0.205 , правильный рост: 0.138\n",
            "Предсказанный рост: -0.037 , правильный рост: 0.376\n",
            "Предсказанный рост: 0.162 , правильный рост: 0.217\n",
            "Предсказанный рост: 0.033 , правильный рост: -0.412\n",
            "Предсказанный рост: 0.688 , правильный рост: 0.444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EDE01h3YAqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "0d08f05e-80ba-4200-c706-53ac79566bc8"
      },
      "source": [
        "pd.DataFrame(historys.mean()).T"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mse</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mse</th>\n",
              "      <th>val_mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.015247</td>\n",
              "      <td>0.015247</td>\n",
              "      <td>0.087506</td>\n",
              "      <td>0.020406</td>\n",
              "      <td>0.020406</td>\n",
              "      <td>0.096352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss       mse       mae  val_loss   val_mse   val_mae\n",
              "0  0.015247  0.015247  0.087506  0.020406  0.020406  0.096352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5D_5QqzOAY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bd698e2-0841-411d-ec7b-5f5f625de944"
      },
      "source": [
        "abs(dataSetFull['AA']).mean()"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13482529832935553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_dumELy17HO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "20cc3dd9-8b80-474d-9a06-6c74cc74458d"
      },
      "source": [
        "historysForGraph"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mse</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mse</th>\n",
              "      <th>val_mae</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.261425</td>\n",
              "      <td>0.261425</td>\n",
              "      <td>0.769045</td>\n",
              "      <td>0.170607</td>\n",
              "      <td>0.170607</td>\n",
              "      <td>0.620612</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.122524</td>\n",
              "      <td>0.122524</td>\n",
              "      <td>0.550083</td>\n",
              "      <td>0.120493</td>\n",
              "      <td>0.120493</td>\n",
              "      <td>0.513308</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.098377</td>\n",
              "      <td>0.098377</td>\n",
              "      <td>0.485241</td>\n",
              "      <td>0.110494</td>\n",
              "      <td>0.110494</td>\n",
              "      <td>0.495784</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.085376</td>\n",
              "      <td>0.085376</td>\n",
              "      <td>0.459553</td>\n",
              "      <td>0.104735</td>\n",
              "      <td>0.104735</td>\n",
              "      <td>0.487009</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.076233</td>\n",
              "      <td>0.076233</td>\n",
              "      <td>0.437531</td>\n",
              "      <td>0.102030</td>\n",
              "      <td>0.102030</td>\n",
              "      <td>0.481762</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss       mse       mae  val_loss   val_mse   val_mae  epoch\n",
              "0  0.261425  0.261425  0.769045  0.170607  0.170607  0.620612      0\n",
              "1  0.122524  0.122524  0.550083  0.120493  0.120493  0.513308      5\n",
              "2  0.098377  0.098377  0.485241  0.110494  0.110494  0.495784     10\n",
              "3  0.085376  0.085376  0.459553  0.104735  0.104735  0.487009     15\n",
              "4  0.076233  0.076233  0.437531  0.102030  0.102030  0.481762     20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAiQxlGIG-BD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "39c9f5f7-3f3d-4b1a-e83a-45c0857ecd70"
      },
      "source": [
        "# График хода обучения\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history/4)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error')\n",
        "  plt.plot(hist['epoch'], hist['mae'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mae'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0, 0.2])\n",
        "  plt.legend()\n",
        "\n",
        "plot_history(historysForGraph)"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_PeqDbPG946",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "aeca96f2-fa10-4d2f-a1a2-fb21e605ab3a"
      },
      "source": [
        "# Предсказание значений\n",
        "preds_test = model.predict(validationData.drop(['AA'], axis = 1, inplace = False)).flatten()\n",
        "# Просмотр прогноза\n",
        "predsData = model.predict(validationData.drop(['AA'], axis = 1, inplace = False))\n",
        "for i in range(20):\n",
        "  print(\"Предсказанный рост:\", round(predsData[i][0], 3), \", правильный рост:\", round(validationData[\"AA\"].values[i], 3))"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Предсказанный рост: 0.205 , правильный рост: 0.138\n",
            "Предсказанный рост: -0.037 , правильный рост: 0.376\n",
            "Предсказанный рост: 0.162 , правильный рост: 0.217\n",
            "Предсказанный рост: 0.033 , правильный рост: -0.412\n",
            "Предсказанный рост: 0.688 , правильный рост: 0.444\n",
            "Предсказанный рост: 0.377 , правильный рост: 0.433\n",
            "Предсказанный рост: -0.081 , правильный рост: -0.09\n",
            "Предсказанный рост: 0.291 , правильный рост: -0.151\n",
            "Предсказанный рост: 0.087 , правильный рост: 0.238\n",
            "Предсказанный рост: -0.129 , правильный рост: -0.324\n",
            "Предсказанный рост: -0.035 , правильный рост: -0.016\n",
            "Предсказанный рост: -0.03 , правильный рост: 0.043\n",
            "Предсказанный рост: -0.007 , правильный рост: -0.048\n",
            "Предсказанный рост: 0.002 , правильный рост: 0.206\n",
            "Предсказанный рост: 0.0 , правильный рост: -0.029\n",
            "Предсказанный рост: -0.128 , правильный рост: -0.461\n",
            "Предсказанный рост: -0.044 , правильный рост: -0.009\n",
            "Предсказанный рост: -0.077 , правильный рост: -0.104\n",
            "Предсказанный рост: -0.1 , правильный рост: -0.073\n",
            "Предсказанный рост: 0.011 , правильный рост: -0.044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ci-3PtJy5QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRxGuqnxdjb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}